\documentclass[12pt]{article}
\usepackage{../../template}
\author{niceguy}
\title{Lecture 19}
\begin{document}
\maketitle

\section{Sampling}
We cannot measure the whole population, so we will have to make do with a subset. So we take samples randomly.

\begin{defn}
	Sample refers to the data $x_1,\dots,x_n$ collected, with random variables $X_1,\dots,X_n$.
\end{defn}

Usually, these data are \textbf{independent identically distributed} (IID). Suppose each $X$ has mean $\mu$ and variance $\sigma^2$.

\subsection{Sample Mean}

The empirical mean is

$$\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i$$
And similarly, the random variable $\overline{X}$ is defined as
$$\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i$$
and obviously
$$E[X] = \mu$$

\subsection{Sample Variance}

$$S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2$$

We want that $E[S^2] = \sigma^2$. Note that
\begin{align*}
	E[S^2] &= E\left[\frac{1}{n-1} \sum_{i=1}^n (X_i^2 - 2X_i\overline{X} + \overline{X}^2)\right] \\
	       &= E\left[\frac{1}{n-1} \left(\sum_{i=1}^n X_i^2\right) - n\overline{X}^2\right] \\
	       &= \frac{1}{n-1}\left(n\mu^2 + n\sigma^2 - n\mu^2 - n\text{var}(\overline{X})\right) \\
	       &= \frac{1}{n-1}\left(n\sigma^2 - n\text{var}\left(\frac{1}{n}\sum_{i=1}^n X_i\right)\right) \\
	       &= \frac{1}{n-1} \left(n\sigma^2 - \frac{1}{n}\sum_{i=1}^n\text{var}(X_i)\right) \\
	       &= \frac{1}{n-1} (n\sigma^2 - \sigma^2) \\
	       &= \sigma^2
\end{align*}

\end{document}
