\documentclass[12pt]{article}
\usepackage{../../template}
\author{niceguy}
\title{Lecture 18}
\begin{document}
\maketitle

\section{Singular Value Decomposition}

Recall the singular values of $T \in \mathcal L(V,W)$ are the eigenvalues of $\sqrt{T^*T} \in \mathcal L(V)$, with $V,W$ being finite dimensional inner product spaces.
$$V = \text{null}(T) \oplus \text{ran}(T^*)$$
$$W = \text{null}(T^*) \oplus \text{ran}(T)$$
$T$ restricts to an isomorphism on $\text{ran}(T^*) \rightarrow \text{ran}(T)$, and
$$\text{null}(T^*T) = \text{null}(T)$$
the same holds for $T^*$ (use $S=T^*$ and consider how the above holds for $S$). In the homework problems, we showed that $T$ gives an isomorphism from $E(\lambda,T^*T) \rightarrow E(\lambda,TT^*)$. We see that
$$v \in E(\lambda,T^*T) \Rightarrow Tv \in (E\lambda,TT^*)$$
because
$$TT^*(Tv) = T(T^*Tv) = T(\lambda v) = \lambda Tv$$
We can use this to get the normal form for $T$. Pick an orthonormal basis $v_1,\dots,v_n$ of $\text{ran}(T^*)$ consisting of eigenvectors of $T^*T$, with eigenvalues $s_1^2,\dots,s_n^2$, the strictly positive singular values.

\begin{lem}
	The vectors $w_i = \frac{1}{s_i}Tv_i$ form an orthonormal basis of $\text{ran}(T)$, consisting of eigenvectors of $TT^*$ and eigenvalues $s_i^2$.
\end{lem}

\begin{proof}
	\begin{align*}
		\langle w_i,w_j \rangle &= \frac{1}{s_is_j} \langle Tv_i,Tv_j \rangle \\
					&= \frac{1}{s_is_j} \langle v_i,T^*Tv_j \rangle \\
					&= \frac{s_j}{s_i} \langle v_i,v_j \rangle \\
					&= \begin{cases} 1 & i = j \\ 0 & i \neq j \end{cases}
	\end{align*}
	We have already checked that $T$ takes $E(s^2,T^*T)$ to $E(s^2,TT^*)$.
\end{proof}

Rearranging yields
$$Tv_i = s_iw_i$$
so
$$T(v) = \sum_{i=1}^k s_i \langle v,v_i \rangle w_i$$

\begin{thm}[Singular Value Decomposition]
	Let $V,W$ be finite dimensional inner product spaces. Then any $T \in \mathcal L(V,W)$ can be written as
	$$T(v) = \sum_{i=1}^k s_i \langle v,v_i \rangle w_i$$
	where $v_1,\dots,v_k$ and $w_1,\dots,w_k$ are orthonormal sets of vectors, and $s_i > 0$. In the expression, $s_i$ are the singular values of $T$, $v_i$ are eignevectors of $T^*T$ for $s_i^2$ and $w_i$ are eignevectors of $TT^*$ for $s_i^2$.
\end{thm}

\begin{proof}
	Given $T$, we have shown how to find such a decomposition. We take $s_i$, the singular values, $v_i$, the eigenvalues of $T^*T$, and put $w_i = \frac{1}{s_i}Tv_i$. Conversely, given the expression in the theorem,
	\begin{align*}
		\langle T^*w_i,v_j \rangle &= \langle w_i,Tv_j \rangle \\
					   &= s_j \langle w_i,w_j \rangle \\
					   &= \begin{cases} 0 & i \neq j \\ s_i & i = j \end{cases}
	\end{align*}
	To show that $T^*w$ is a multiples of $v_i$, in fact $T^*w_i = s_iv_i$. Then this gives
	$$T^*T(v_i) = T^*(s_iw_i) = s_i^2v_i$$
	$$TT^*(w_i) = T(s_iv_i) = s_i^2w_i$$
\end{proof}

Note that we do not need to compute $\sqrt{T^*T}$, and the decomposition is not really unique, as it is dependent on a choice of unit eigenvectors. In the case of normal operators $T$, we can take $v_i$ to be the unit eigenvectors of $T$, eigenvalue $\lambda$. Singular values are $s_i = |\lambda_i|$ and
$$w_i = \frac{1}{s_i}Tv_i = \frac{\lambda_i}{|\lambda_i|}v_i$$
Indeed, singular value decomposition is essentially spectral resolution.

\section{Singluar Value Decomposition For Matrices}

Suppose $A \in M_{n\times n}(\F)$ is invertible, with $\F = \R$ or $\F = \C$. Then all singular values are strictly positive. Let $v_1,\dots,v_n$ be an orthonormal basis of eigenvectors of $A^*A$ for the eigenvalues $s_1^2,\dots,s_n^2$. Let $w_i = \frac{1}{s_i}Av_i$. Let $U_1$ be the unitary matrix having $v_1,\dots,v_n$ as columns, and similarly $U_2$ be the unitary matrix having $w_1,\dots,w_n$ as columns. Let $D$ be a matrix such that $D_{ij} = \delta_{ij}s_i$. Then $Av_i = s_iw_i$ means
$$AU_1 = U_2D$$
or
$$A = U_2DU_1^{-1}$$

\begin{thm}[Singular Value Decomposition for Invertible Matrix]
	Every invertible $A \in M_{n\times n}(\F)$ can be written as
	$$A = U_2DU_1^{-1}$$
	where $U_1,U_2$ are unitary, and $D$ is diagonal with strictly positive entries.
\end{thm}

Note that this is not unique.

\begin{ex}
	Find the singular value decomposition of
	$$A = \begin{pmatrix} 4 & 0 \\ 3 & -5 \end{pmatrix}$$
	We have
	$$A^*A = \begin{pmatrix} 4 & 3 \\ 0 & -5 \end{pmatrix} \begin{pmatrix} 4 & 0 \\ 3 & -5 \end{pmatrix} = \begin{pmatrix} 25 & -15 \\ -15 & 25 \end{pmatrix}$$
	with the eigenvalues $s_1^2 = 40, s_2^2 = 10$. The eigenvectors are
	$$v_1 = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ -1 \end{pmatrix}, v_2 = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & 1 \end{pmatrix}$$
	So
	$$w_1 = \frac{1}{2\sqrt{10}} \begin{pmatrix} 4 & 0 \\ 3 & -5 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & -1 \end{pmatrix} = \frac{1}{\sqrt{5}} \begin{pmatrix} 1 \\ 2 \end{pmatrix}$$
	and
	$$w_2 = \frac{1}{\sqrt{10}} \begin{pmatrix} 4 & 0 \\ 3 & -5 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{\sqrt{5}} \begin{pmatrix} 2 \\ -1 \end{pmatrix}$$
	So
	$$A = U_2DU_1^{-1} = \frac{1}{\sqrt{5}} \begin{pmatrix} 1 & 2 \\ 2 & -1 \end{pmatrix} \sqrt{10} \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix}$$
\end{ex}

If you have the SVD, you also get polar decomposition for free.
$$A = U_2DU_1^{-1} = (U_2U_1^{-1})(U_1DU_1^{-1}) = UR$$
where the first matrix is unitary and the second is positive if you look hard enough. \\
More generally, consider $A \in M_{m \times n}(\F)$. THink of it as $A: \F^n \rightarrow \F^m$. As before pick an orthonormal basis $v_1,\dots,v_k$ of $\text{ran}(A^*) = \text{null}(A)^\perp$, and let $w_i = \frac{1}{s_i}Av_i$ where $s_i$ denote the singular values. Extend $v_1,\dots,v_k$ to an orthonormal basis $v_1,\dots,v_n$, and extend $w_1,\dots,w_k$ similarly to $w_1,\dots,w_m$. Let $U_1 \in M_{n \times n}(\F)$ have $v_1,\dots,v_n$ as columns, and $U_2 \in M_{m \times m}(\F)$ have $w_1,\dots,w_m$ as columns. Let $D \in M_{m \times n}(\F)$ be the matrix with
$$D_{ij} = \begin{cases} s_i & i = j \leq k \\ 0 & \text{else} \end{cases}$$
Then

\begin{thm}[Singular Value Decomposition for Non Square Matrices]
	Every $A \in M_{m \times n}(\F)$ can be written as
	$$A = U_2DU_1^{-1}$$
	where $U_1 \in M_{n \times n}(\F)$, $U_2 \in M_{m \times m}(\F)$ are unitary, and $D \in M_{m \times n}(\F)$ has only nonzero entries at $D_{ii} = s_i$, the strictly positive singular values.
\end{thm}

\begin{ex}
	$$A = \begin{pmatrix} 0 & 1 \\ 0 & 1 \\ 1 & 0 \end{pmatrix}$$
	Then
	$$A^* = \begin{pmatrix} 0 & 0 & 1 \\ 1 & 1 & 0 \end{pmatrix}$$
	and
	$$A^*A = \begin{pmatrix} 1 & 0 \\ 0 & 2 \end{pmatrix}$$
	with singular values $s_1=1,s_2=\sqrt{2}$ and eigenvectors $\begin{pmatrix} 1 & 0 \end{pmatrix}$ and $\begin{pmatrix} 0 & 1 \end{pmatrix}$. Now
	$$w_1 = \frac{1}{s_1}Av_1 = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}, w_2 = \frac{1}{s_2}Av_2 = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix}$$
	We complete the orthonormal basis by
	$$w_3 = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ -1 \\ 0\end{pmatrix}$$
	Then
	$$A = \begin{pmatrix} 0 & \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\ 0 & \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ 1 & 0 & 0 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & \sqrt{2} \\ 0 & 0 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$$
\end{ex}
\end{document}
