\documentclass[answers]{exam}
\usepackage{../../template}
\title{Homework 1}
\author{niceguy}
\begin{document}
\maketitle

\begin{questions}

\question{Calculate the determinant of the following complex matrix.
$$\begin{pmatrix} 0 & i & 2 & -1 \\
i & 5 & i & i \\
0 & 3 & 1+i & 2 \\
0 & -2i & 1 & 4-i\end{pmatrix}$$
}

\begin{solution}
	Expanding along the first column, the determinant is equal to
	$$-i\det\begin{pmatrix} i & 2 & -1 \\
		3 & 1+i & 2 \\
	-2i & 1 & 4-i\end{pmatrix}$$
	where the determinant of the 3 by 3 matrix is
	$$i(1+i)(4-i) + 2\times2(-2i) - 1\times3\times1 -i\times2\times1 - 2\times3(4-i) + 1(1+i)(-2i) = -i-28$$
	The desired determinant is then
	$$-i(-i-28) = -1+28i$$
\end{solution}

\question{For $n=1,2,\dots$ consider the $n\times n$ matrix
	$$A_n = \begin{pmatrix} 2\cos\theta & 1 & 0 & \dots & 0 & 0 \\
		1 & 2\cos\theta & 1 & \dots & 0 & 0 \\
		0 & 1 & 2\cos\theta & \dots & 0 & 0 \\
		\dots & \dots & \dots & \dots & \dots & \dots \\
		0 & 0 & 0 & \dots & 2\cos\theta & 1 \\
	0 & 0 & 0 & \dots & 1 & 2\cos\theta\end{pmatrix}$$
}

\begin{parts}
	\part{Show that $\det(A_{n+2}) - 2\cos\det(A_{n+1}) + \det(A_{n+1}) = 0$}\label{a}

	\begin{solution}
		Expanding along the first row,
		\begin{align*}
			\det(A_{n+2}) &= 2\cos\theta\det(A_{n+1}) - \det\begin{pmatrix} 1 & P \\ Q & A_n\end{pmatrix} \\
				      &= 2\cos\theta\det(A_{n+1}) - \det(A_n) \\
			\det(A_{n+2}) - 2\cos\theta\det(A_{n+1}) + \det(A_n) &= 0
		\end{align*}
		Where $P$ is the $1\times n$ row matrix where the first entry is 1 and the rest are 0, and $Q$ is the $n \times 1$ column matrix whose entries are all 0. The secondequality comes from expanding along the first column.
	\end{solution}

	\part{Use (\ref{a}) and induction to show
		$$\det(A_n) = \frac{\sin((n+1)\theta)}{\sin\theta}$$
	}

	\begin{solution}
		For $n=1$,
		$$A_1 = \begin{pmatrix} 2\cos\theta \end{pmatrix}$$
		where the determinant is obviously $2\cos\theta$. Then
		$$\frac{\sin(2\theta)}{\sin\theta} = \frac{2\sin\theta\cos\theta}{\sin\theta} = 2\cos\theta$$
		so the identity holds for $n=1$. \\
		For $n=2$, 
		$$A_2 = \begin{pmatrix} 2\cos\theta & 1 \\ 1 & 2\cos\theta\end{pmatrix}$$
		where the determinant is obviously $4\cos^2\theta - 1$. Then
		$$\frac{\sin(3\theta)}{\sin\theta} = \frac{\sin(2\theta)\cos\theta + \sin\theta\cos(2\theta)}{\sin\theta} = \frac{2\sin\theta\cos^2\theta + \sin\theta(2\cos^2\theta-1)}{\sin\theta}$$
		which simplifies to
		$$4\cos^2\theta - 1$$
		Let this identity hold for $n=k$ and $n=k+1$. Then
		\begin{align*}
			\det(A_{k+2}) &= 2\cos\theta\det(A_{k+1}) - \det(A_k) \\
				      &= \frac{2\cos\theta\sin((k+2)\theta) - \sin((k+1)\theta)}{\sin\theta} \\
				      &= \frac{\sin((k+3)\theta) + \sin((k+1)\theta) - \sin((k+1)\theta)}{\sin\theta} \\
				      &= \frac{\sin((k+3)\theta)}{\sin\theta}
		\end{align*}
		which shows that the identity holds for $n=k+3$. By mathematical induction, it holds for all $n = 1,2,\dots$.
	\end{solution}
		
\end{parts}

\question{Let $T \in \mathcal{L}(V)$ be a linear transformation, and $T^*\in\mathcal{L}(V^*)$ the dual transformation. Show that
	$$\det(T^*) = \det(T)$$
}

\begin{solution}
	The expression of the determinant involves the constants $A_{ij}$. For $T$ defined by
	$$T(\hat{e}_i) = \vec{v}_i$$
	the determinant of $T$ is the determinant of its matrix
	$$\det(v_1,v_2,\dots,v_n)$$
	where the constants are
	$$\vec{v}_j = \sum_i A_{ij}\hat{e}_i$$
	Similarly for the dual, we have
	$$T^*(\phi_i) = \phi_i \circ T$$
	Note that for an arbitrary $\hat{e}_j$,
	\begin{align*}
		T^*(\phi_i) &= \phi_i \circ T(\hat{e}_j) \\
			    &= \phi_i(\vec{v}_j) \\
			    &= \phi_i\left(\sum_kA_{kj}\hat{e}_k\right) \\
			    &= \sum_kA_{kj}\phi_i\hat{e}_k \\
			    &= A_{ij}
	\end{align*}
	Therefore,
	$$T^*(\phi_i) = \sum_j A_{ij}\phi_j$$
	Then the formula for the $\det(T*)$ is the same as that of $\det(T)$, so
	$$\det(T) = \det(T^*)$$
\end{solution}

\question{}

\begin{parts}
\part{Suppose $A\in M_{n\times n}(F)$ has 'block upper triangular diagonal form'
	$$A = \begin{pmatrix} A' & * \\ 0 & A'' \end{pmatrix}$$
	where $A' \in M_{k\times k}(F)$ and $A'' \in M_{l\times l}(F)$, while $*$ stands for `anything'. Prove that
	$$\det(A) = \det(A')\det(A'')$$
}

\begin{solution}
	Let $S$ be the set of permutations. Let $\mathcal{S} \subset S$ be the subset where $\forall\sigma\in\mathcal{S},i\in(1,2,\dots,k)$,
	$$\sigma(k) \in (1,2,\dots,k)$$
	Then define $\mathcal{S}' = S-\mathcal{S}$ (or $S\backslash\mathcal{S}$). The left hand side then becomes
	$$\det(A) = \sum_{\sigma\in\mathcal{S}} \text{sign}(\sigma)\prod_iA_{\sigma(i),i} + \sum_{\sigma\in\mathcal{S}'} \text{sign}(\sigma)\prod_iA_{\sigma(i),i}$$
	Note that for all permutations in $\mathcal{S}'$, there exists an $i \in (1,2,\dots,k)$ where
	$$\sigma(i) \in (k+1,k+2,\dots,k+l)$$
	i.e. $A_{\sigma(i),i} = 0$. Thus the second term goes to zero. \\
	Note that permutations $\tau$ for $(1,2,\dots,k)$ and $\tau'$ for $(1,2,\dots,l)$ can be combined to exactly form all permutations in $\mathcal{S}$. Moreover, if $\tau$ and $\tau'$ are combined to form $\sigma$, then
	$$\text{sign}(\tau)\times\text{sign}(\tau') = \text{sign}(\sigma)$$
	Then the right hand side of the equation becomes
	\begin{align*}
		\det(A')\det(A'') &= \sum_\tau \text{sign}(\tau)\prod_i A'_{\tau(i),i} + \sum_{\tau'} \text{sign}(\tau')\prod_i A''_{\tau'(i),i} \\
				  &= \sum_{\sigma\in\mathcal{S}} \text{sign}(\sigma) \prod_i A_{\sigma(i),i} \\
				  &= \det(A)
	\end{align*}
\end{solution}

\part{Let $V$ be a finite-dimensional vector space, and $T\in\mathcal{L}(V)$ a linear transformation. Suppose $W\subseteq V$ is a $T$-invariant subspace. Let
	$$S = T|_W\in\mathcal{L}(W)$$
	be the restriction, and
	$$U \in \mathcal{L}(V/W)$$
	the induced transformation on the quotient space (i.e., $U$ takes $v+W$ to $Tv+W$). Prove that
	$$\det(T) = \det(S)\det(U)$$
}

\begin{solution}
	We wish to show that $T$ is in the form of $A$ in the part above, where $A'$ is the matrix for $S$ and $A''$ is the matrix for $U$. The desired result follows in this case.
	We use the basis $(e_1, e_2, \dots, e_m, \dots, e_n)$, where $(e_1,e_2,\dots,e_m)$ is the basis for $W$. Then we define $X$ as the space spanned by $(e_{m+1},e_{m+2},\dots,e_n)$. Note that since $W$ is $T$-invariant, this corresponds to the 0 matrix in $A$, as $T(w)\forall w\in W$ does not map to any entry in $X$, or $T(e_i)$ does not map to any vector with a nonzero $e_j$ component where $1\leq i\leq n$ and $n+1\leq j\leq m$. The restriction $S$ then obviously has the matrix $A'$, as $S(e_i) = T(e_i)$ where $i$ is defined as above. Finally, let $v=w+x$ where $w\in W$ and $x\in X$. Define $T'\in\mathcal{L}(V)$ such that if
	$$T(v) = \sum_{i=1}^n a_ie_i$$
	then
	$$T'(v) = \sum_{i=m+1}^n a_ie_i$$
	Then
	$$U(v+W) = U(x+W) = Tx+W = T'x+W$$
	since the components of $W$ can be absorbed into $W$. Then defining the basis vectors as
	$$e'_i = e_i+W$$
	for $m+1\leq i\leq n$, then
	$$U(e'_i) = T'e_i+W$$
	So $U$ and $T'$ share the same matrix. Since $T'$ is the linear transformation $T$ whose domain and range are restricted to $X$, the matrix for $T'$ is $A''$.
\end{solution}

\end{parts}

\end{questions}
\end{document}
