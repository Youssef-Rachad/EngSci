\documentclass[12pt]{article}
\usepackage{../../template}
\author{niceguy}
\title{Lecture 3}
\begin{document}
\maketitle

\section{Recap}

Determinants are

\begin{itemize}
	\item Multi-linear in columns \\
	\item Vanishes when two columns are equal \\
	\item $\det(I) = 1$
\end{itemize}

The formula is
$$\det(A) = \sum_\sigma \text{sign}(\sigma) \prod_i A_{\sigma(i),i}$$

From the formula, we see

$$\det{A^T} = \det{A}$$

In the case of $n=2$,
$$\det(A) = A_{11}A_{22} - A_{12}A_{21}$$

And for $n=3$,
$$\det(A) = A_{11}A_{22}A_{33} + A_{12}A_{23}A_{31} + A_{13}A_{21}A_{32} - A_{11}A_{23}A_{32} - A_{12}A_{21}A_{33} - A_{13}A_{22}A_{31}$$

\section{Determinant Theorems}

\begin{thm}
	If $A$ is upper triangular (or lower triangular), then $\det(A)$ is the product of diagonal entries.
	$$\det(A) = \prod_i A_{ii}$$
\end{thm}

Proof: \\
Given $A$ is upper triangular, $A_{ij} = 0 \forall i>j$. Then the only nonzero term in the summation is where $\sigma(i)\leq i\forall i$. One can easily prove $\sigma(i)=i$ by induction (same for lower triangular, where $\sigma(i)\geq i$. \\
Remark: \\
$$A=\begin{pmatrix} A' & B \\ 0 & A''\end{pmatrix}$$
then
$$\det(A) = \det(A')\det(A'')$$
and similarly
$$A=\begin{pmatrix} A'& * & *\\ 0 & A'' & * \\ 0 & 0 & A'''\end{pmatrix}$$
then
$$\det(A) = \det(A')\det(A'')\det(A''')$$

The column operations on a matrix $A$ are

\begin{enumerate}
	\item Interchanging the columns \\
	\item Multiplying a column by some $\lambda\neq0$ \\
	\item Adding a multiple of column to another column
\end{enumerate}

which can be thought of a change of basis. Thus rank is invariant under column operations. Similarly, we have row operations R1, R2, R3. \\
We have proven C1 flips the sign of $\det(A)$. By observation, C2 scales $\det(A)$ by $\lambda$. Finally, C3 doesn't change the determinant, as it is multilinear. In any case, $\det(A)$ is either consistently zero or nonzero.

\begin{thm}
	For $A\in M_{n\times n}(\F)$
	$$\det(A)\neq0 \Leftrightarrow A \text{ is invertible}$$
\end{thm}

Proof: \\
Using row and column operations, every $A$ can be made diagonal. We can do this by considering an arbitrary $A_{ij}\neq0$. Using row and column operations, it can be moved to the top left corner, where all other elements on the first row and column can be removed. Then the same is done for $(2,2)$ and so on. Then $\det(A)\neq0\Leftrightarrow\det(A')\neq0$. But $\det(A')$ is the product of diagonal entries of $A'$ (any permutation where $\exists i:\sigma(i)\neq i$ vanishes), so it is nonzero iff all diagonal entries are nonzero, which is equivalent to $A'$ being invertible. This is equivalent to $A$ being invertible, as rank is preserved under row and column operations.

\begin{thm}
	For $A,B\in M_{n\times n}(\F)$,
	$$\det(AB) = \det(A)\det(B)$$
	in particular, $\det(A^{-1}) = \det(A)^{-1}$ if $A$ is invertible.
\end{thm}

Proof: \\
If $A$ is not invertible, then $AB$ is not invertible, so both sides are equal to 0. Thus we assume $\det(A)\neq0$. Define a multilinear functional
$$\phi:\F^n\times\dots\times\F^n\rightarrow\F, (w_1,\dots,w_n) \mapsto \frac{\det(Aw_1,\dots,Aw_n)}{\det(A)}$$
Note that $\phi$ vanishes when $\exists i\neq j:w_i=w_j$. If $w_i=e_i$, then the numerator is the determinant of the columns of $A$, so $\phi=1$. Then we know
$$\phi(w_1,\dots,w_n) = \det(w_1,\dots,w_n)$$
and rearranging yields
$$\det(w_1,\dots,w_n) = \frac{\det(Aw_1,\dots,Aw_n)}{\det(A)}$$
Choosing $w_i$ to be the $i$th column of $B$ completes the proof (the numerator becomes the columns of $AB$). \\
Consequence: \\
For invertible $C$,
$$\det(CAC^{-1}) = \det(C)\det(A)\det(C^{-1}) = \det(A)$$

\begin{defn}
	For finite-dimensional vector space $V$ over $\F$, $T\in\mathcal{L}(V)$, define $\det(T)=\det(A)$ when $A\in M_{n\times n}(\F)$ is the matrix of $T$ in the same basis of $V$.
\end{defn}

From this we see
$$T \text{ invertible } \Leftrightarrow \det(T)\neq 0$$
$$\det(TS) = \det(T)\det(S)$$

\begin{ex}
	In $\Z_7$,
	$$\det\begin{pmatrix} 3 & 1 & 5 & 2 \\ 2 & 2 & 5 & 3 \\ 1 & 3 & 0 & 4 \\ 0 & 4 & 1 & 6\end{pmatrix}$$
	Using row operations the determinant is equal to
	\begin{align*}
		&= -\det\begin{pmatrix} 1 & 3 & 0 & 4 \\ 2 & 2 & 5 & 3 \\ 3 & 1 & 5 & 2 \\ 0 & 4 & 1 & 6\end{pmatrix} \\
		&= -\det\begin{pmatrix} 1 & 3 & 0 & 4 \\ 0 & 3 & 5 & 2 \\ 0 & 6 & 5 & 4 \\ 0 & 4 & 1 & 6\end{pmatrix} \\
		&= -\det\begin{pmatrix} 1 & 3 & 0 & 4 \\ 0 & 3 & 5 & 2 \\ 0 & 0 & 2 & 0 \\ 0 & 0 & 0 & 1\end{pmatrix} \\
		&= 1
	\end{align*}
	Alternatively, the non bozo way is by putting this into a calculator and modding the final result with 7.
\end{ex}

\begin{ex}
	\begin{align*}
		\det\begin{pmatrix} 2 & 0 & 0 & 1 \\ 0 & 1 & 3 & -3 \\ -2 & -3 & -5 & 2 \\ 4 & -4 & 4 & -6 \end{pmatrix}&= \det\begin{pmatrix} 2 & 0 & 0 & 1 \\ 0 & 1 & 3 & -3 \\ 0 & -3 & -5 & 3 \\ 0 & -4 & 4 & -8\end{pmatrix} \\
				      &= 2\det\begin{pmatrix}1 & 3 & -3 \\ -3 & -5 & 3 \\ -4 & 4 & -8\end{pmatrix} \\
				      &= 16
	\end{align*}
\end{ex}

Another method is to use linearity in columns/rows.

$$\det(A) = A_{11}\det\begin{pmatrix}1 & A_{12} & \dots & A_{1n} \\ 0 & A_{22} & \dots & \vdots \\ \vdots & \vdots & \ddots & \vdots \\ 0 & A_{n2} & \dots & A_{nn}\end{pmatrix} + A_{21} \begin{pmatrix} 0 & A_{12} & \dots & A_{1n} \\ 1 & A_{22} & \dots & A_{2n} \\ 0 & A_{32} & \dots & A_{3n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & \dots & \dots & A_{nn}\end{pmatrix} + \dots$$

Note that for all the determinants, row operations can be used to switch the $i$th row to the 1st row while preserving order for all other rows. Substitution for block matrices can then be used. Additional signs then come from the switching of rows. More generally, we have

$$\det(A) = \sum_{i=1}^n (-1)^{i+j}A_{ij}\det(A^{[ij]})$$
Note that $A^{[ij]}$ is $A$ with row $i$ and column $j$ removed. We can also sum over $j$.

\begin{defn}
	The cofactor $c_{ij}$ is defined as
	$$c_{ij} = (-1)^{i+j} \det(A^{[ij]})$$
\end{defn}

\begin{ex}
	Continuing the last example,
	\begin{align*}
		\det\begin{pmatrix}2 & 0 & 0 & 1 \\ 0 & 1 & 3 & -3 \\ -2 & -3 & -5 & 2 \\ 4 & -4 & 4 & -6\end{pmatrix} &= 2\det\begin{pmatrix} 1 & 3 & -3 \\ -3 & -5 & 2 \\ -4 & 4 & -6\end{pmatrix} - \det\begin{pmatrix} 0 & 1 & 3 \\ -2 & -3 & -5 \\ 4 & -4 & 4\end{pmatrix} \\
				     &= 16
	\end{align*}
\end{ex}

\begin{thm}
	Cramer's rule. Let $A\in M_{n\times n}(\F)$ be invertible, with columns $v_1,\dots,v_n$. Then the unique solution $x$ for $Ax=b$ is given by
	$$x_i = \frac{\det(v_1,\dots,v_{i-1},b,v_{i+1},\dots,v_n)}{\det(A)}$$
\end{thm}

Proof: \\
Let $x$ be the unqiue solution of $Ax=b$. That is,
$$\sum_i x_iv_i = b$$
Then expanding using linearity,
\begin{align*}
	\det(v_1,\dots,v_{i-1},b,v_{i+1},\dots,v_n) &= \sum_j x_j\det(v_1,\dots,v_{i-1},v_j,v_{i+1},\dots,v_n) \\
						    &= x_i\det(v_1,\dots,v_{i-1},v_i,v_{i+1},\dots,v_n) \\
						    &= x_i\det(A)
\end{align*}

\begin{ex}
	$$A=\begin{pmatrix} 3 & 0 & -1 \\ 0 & 2 & 4 \\ -3 & -2 & 1\end{pmatrix}$$
	and
	$$b = \begin{pmatrix} 1 \\ 7 \\ -1\end{pmatrix}$$
	We can find $\det(A)$ to be $24$. Plugging the numbers in yields
	$$x_1 = \frac{11}{12}, x_2 = 0, x_3 = \frac{7}{4}$$
\end{ex}

Note that Cramer's rule is $O(n!\times n)$, so don't actually use it.
\end{document}
